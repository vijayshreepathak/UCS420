{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4F3Yx-wxDomJ",
        "outputId": "de2b9d7c-0196-426c-cd46-66d2afbf41b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Text:\n",
            "technology is one of my favorite topics because it constantly evolves\n",
            " and shapes our daily lives from smartphones to artificial intelligence it\n",
            "  makes tasks faster and more efficient i find it fascinating how technology\n",
            "   connects people across the world in real time it also plays a major role in\n",
            "    fields like medicine education and entertainment new innovations like\n",
            "     virtual reality and smart devices continue to change how we experience the\n",
            "      world overall technology is an exciting and powerful tool that keeps\n",
            "       pushing the limits of what’s possible\n",
            "\n",
            "\n",
            "Tokens:\n",
            "['technology', 'is', 'one', 'of', 'my', 'favorite', 'topics', 'because', 'it', 'constantly', 'evolves', 'and', 'shapes', 'our', 'daily', 'lives', 'from', 'smartphones', 'to', 'artificial', 'intelligence', 'it', 'makes', 'tasks', 'faster', 'and', 'more', 'efficient', 'i', 'find', 'it', 'fascinating', 'how', 'technology', 'connects', 'people', 'across', 'the', 'world', 'in', 'real', 'time', 'it', 'also', 'plays', 'a', 'major', 'role', 'in', 'fields', 'like', 'medicine', 'education', 'and', 'entertainment', 'new', 'innovations', 'like', 'virtual', 'reality', 'and', 'smart', 'devices', 'continue', 'to', 'change', 'how', 'we', 'experience', 'the', 'world', 'overall', 'technology', 'is', 'an', 'exciting', 'and', 'powerful', 'tool', 'that', 'keeps', 'pushing', 'the', 'limits', 'of', 'what', '’', 's', 'possible']\n",
            "\n",
            "Filtered Words:\n",
            "['technology', 'one', 'favorite', 'topics', 'constantly', 'evolves', 'shapes', 'daily', 'lives', 'smartphones', 'artificial', 'intelligence', 'makes', 'tasks', 'faster', 'efficient', 'find', 'fascinating', 'technology', 'connects', 'people', 'across', 'world', 'real', 'time', 'also', 'plays', 'major', 'role', 'fields', 'like', 'medicine', 'education', 'entertainment', 'new', 'innovations', 'like', 'virtual', 'reality', 'smart', 'devices', 'continue', 'change', 'experience', 'world', 'overall', 'technology', 'exciting', 'powerful', 'tool', 'keeps', 'pushing', 'limits', '’', 'possible']\n",
            "Word Frequency Distribution (Excluding Stopwords):\n",
            "Counter({'technology': 3, 'world': 2, 'like': 2, 'one': 1, 'favorite': 1, 'topics': 1, 'constantly': 1, 'evolves': 1, 'shapes': 1, 'daily': 1, 'lives': 1, 'smartphones': 1, 'artificial': 1, 'intelligence': 1, 'makes': 1, 'tasks': 1, 'faster': 1, 'efficient': 1, 'find': 1, 'fascinating': 1, 'connects': 1, 'people': 1, 'across': 1, 'real': 1, 'time': 1, 'also': 1, 'plays': 1, 'major': 1, 'role': 1, 'fields': 1, 'medicine': 1, 'education': 1, 'entertainment': 1, 'new': 1, 'innovations': 1, 'virtual': 1, 'reality': 1, 'smart': 1, 'devices': 1, 'continue': 1, 'change': 1, 'experience': 1, 'overall': 1, 'exciting': 1, 'powerful': 1, 'tool': 1, 'keeps': 1, 'pushing': 1, 'limits': 1, '’': 1, 'possible': 1})\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Q1. Write a unique paragraph (5-6 sentences) about your favorite topic (e.g., sports,\n",
        "# technology, food, books, etc.).\n",
        "# 1. Convert text to lowercase and remove punctuaƟon.\n",
        "# 2. Tokenize the text into words and sentences.\n",
        "# 3. Remove stopwords (using NLTK's stopwords list).\n",
        "# 4. Display word frequency distribuƟon (excluding stopwords).\n",
        "\n",
        "\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from collections import Counter\n",
        "\n",
        "# NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Sample text\n",
        "text = \"\"\"Technology is one of my favorite topics because it constantly evolves\n",
        " and shapes our daily lives. From smartphones to artificial intelligence, it\n",
        "  makes tasks faster and more efficient. I find it fascinating how technology\n",
        "   connects people across the world in real time. It also plays a major role in\n",
        "    fields like medicine, education, and entertainment. New innovations like\n",
        "     virtual reality and smart devices continue to change how we experience the\n",
        "      world. Overall, technology is an exciting and powerful tool that keeps\n",
        "       pushing the limits of what’s possible.\n",
        "\"\"\"\n",
        "\n",
        "# 1. Convert text to lowercase and remove punctuation\n",
        "text_lower = text.lower()\n",
        "text_clean = text_lower.translate(str.maketrans('', '', string.punctuation))\n",
        "print(\"Cleaned Text:\")\n",
        "print(text_clean)\n",
        "\n",
        "# 2. Tokenize the text into words and sentence\n",
        "words = word_tokenize(text_clean)\n",
        "sentences = sent_tokenize(text)\n",
        "print(\"\\nTokens:\")\n",
        "print(words)\n",
        "\n",
        "# 3. Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_words = [word for word in words if word not in stop_words]\n",
        "print(\"\\nFiltered Words:\")\n",
        "print(filtered_words)\n",
        "\n",
        "# 4. Display word frequency distribution\n",
        "word_freq = Counter(filtered_words)\n",
        "print(\"Word Frequency Distribution (Excluding Stopwords):\")\n",
        "print(word_freq)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2: Stemming and LemmaƟzaƟon\n",
        "# 1. Take the tokenized words from QuesƟon 1 (aŌer stopword removal).\n",
        "# 2. Apply stemming using NLTK's PorterStemmer and LancasterStemmer.\n",
        "# 3. Apply lemmaƟzaƟon using NLTK's WordNetLemmaƟzer.\n",
        "# 4. Compare and display results of both techniques.\n",
        "# Initialize stemmers and lemmatizer\n",
        "porter_stemmer = PorterStemmer()\n",
        "lancaster_stemmer = LancasterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Apply stemming using PorterStemmer and LancasterStemmer\n",
        "porter_stemmed = [porter_stemmer.stem(word) for word in filtered_words]\n",
        "lancaster_stemmed = [lancaster_stemmer.stem(word) for word in filtered_words]\n",
        "\n",
        "# Apply lemmatization using WordNetLemmatizer\n",
        "lemmatized = [lemmatizer.lemmatize(word) for word in filtered_words]\n",
        "\n",
        "# Compare and display results of both techniques\n",
        "print(\"\\nStemming (PorterStemmer):\", porter_stemmed)\n",
        "print(\"\\nStemming (LancasterStemmer):\", lancaster_stemmed)\n",
        "print(\"\\nLemmatization:\", lemmatized)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD7RCrq6Fphk",
        "outputId": "d9803da6-b6da-4812-a6d8-53c300efa04f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Stemming (PorterStemmer): ['technolog', 'one', 'favorit', 'topic', 'constantli', 'evolv', 'shape', 'daili', 'live', 'smartphon', 'artifici', 'intellig', 'make', 'task', 'faster', 'effici', 'find', 'fascin', 'technolog', 'connect', 'peopl', 'across', 'world', 'real', 'time', 'also', 'play', 'major', 'role', 'field', 'like', 'medicin', 'educ', 'entertain', 'new', 'innov', 'like', 'virtual', 'realiti', 'smart', 'devic', 'continu', 'chang', 'experi', 'world', 'overal', 'technolog', 'excit', 'power', 'tool', 'keep', 'push', 'limit', '’', 'possibl']\n",
            "\n",
            "Stemming (LancasterStemmer): ['technolog', 'on', 'favorit', 'top', 'const', 'evolv', 'shap', 'dai', 'liv', 'smartphon', 'art', 'intellig', 'mak', 'task', 'fast', 'efficy', 'find', 'fascin', 'technolog', 'connect', 'peopl', 'across', 'world', 'real', 'tim', 'also', 'play', 'maj', 'rol', 'field', 'lik', 'medicin', 'educ', 'entertain', 'new', 'innov', 'lik', 'virt', 'real', 'smart', 'dev', 'continu', 'chang', 'expery', 'world', 'overal', 'technolog', 'excit', 'pow', 'tool', 'keep', 'push', 'limit', '’', 'poss']\n",
            "\n",
            "Lemmatization: ['technology', 'one', 'favorite', 'topic', 'constantly', 'evolves', 'shape', 'daily', 'life', 'smartphones', 'artificial', 'intelligence', 'make', 'task', 'faster', 'efficient', 'find', 'fascinating', 'technology', 'connects', 'people', 'across', 'world', 'real', 'time', 'also', 'play', 'major', 'role', 'field', 'like', 'medicine', 'education', 'entertainment', 'new', 'innovation', 'like', 'virtual', 'reality', 'smart', 'device', 'continue', 'change', 'experience', 'world', 'overall', 'technology', 'exciting', 'powerful', 'tool', 'keep', 'pushing', 'limit', '’', 'possible']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3. Regular Expressions and Text Spliƫng\n",
        "# 1. Take their original text from QuesƟon 1.\n",
        "# 2. Use regular expressions to:\n",
        "# a. Extract all words with more than 5 leƩers.\n",
        "# b. Extract all numbers (if any exist in their text).\n",
        "# c. Extract all capitalized words.\n",
        "# 3. Use text spliƫng techniques to:\n",
        "# a. Split the text into words containing only alphabets (removing digits and special\n",
        "# characters).\n",
        "# b. Extract words starƟng with a vowel.\n",
        "\n",
        "# 1. Use regular expressions to extract:\n",
        "# a. All words with more than 5 letters\n",
        "long_words = re.findall(r'\\b\\w{6,}\\b', text_clean)\n",
        "print(\"\\nWords with more than 5 letters:\", long_words)\n",
        "\n",
        "# b. All numbers\n",
        "numbers = re.findall(r'\\b\\d+\\b', text_clean)\n",
        "print(\"\\nNumbers found in text:\", numbers)\n",
        "\n",
        "# c. All capitalized words\n",
        "capitalized_words = re.findall(r'\\b[A-Z][a-z]*\\b', text_clean)\n",
        "print(\"\\nCapitalized words:\", capitalized_words)\n",
        "\n",
        "# 2. Use text splitting techniques:\n",
        "# a. Split the text into words containing only alphabets\n",
        "alphabetic_words = re.findall(r'\\b[a-zA-Z]+\\b', text_clean)\n",
        "print(\"\\nAlphabetic words:\", alphabetic_words)\n",
        "\n",
        "# b. Extract words starting with a vowel\n",
        "vowel_words = re.findall(r'\\b[aeiouAEIOU]\\w*\\b', text_clean)\n",
        "print(\"\\nWords starting with a vowel:\", vowel_words)\n"
      ],
      "metadata": {
        "id": "wN7ZgUW1Dvfr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53adcc61-906f-4ea9-ba37-6537cadbd95b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Words with more than 5 letters: ['technology', 'favorite', 'topics', 'because', 'constantly', 'evolves', 'shapes', 'smartphones', 'artificial', 'intelligence', 'faster', 'efficient', 'fascinating', 'technology', 'connects', 'people', 'across', 'fields', 'medicine', 'education', 'entertainment', 'innovations', 'virtual', 'reality', 'devices', 'continue', 'change', 'experience', 'overall', 'technology', 'exciting', 'powerful', 'pushing', 'limits', 'possible']\n",
            "\n",
            "Numbers found in text: []\n",
            "\n",
            "Capitalized words: []\n",
            "\n",
            "Alphabetic words: ['technology', 'is', 'one', 'of', 'my', 'favorite', 'topics', 'because', 'it', 'constantly', 'evolves', 'and', 'shapes', 'our', 'daily', 'lives', 'from', 'smartphones', 'to', 'artificial', 'intelligence', 'it', 'makes', 'tasks', 'faster', 'and', 'more', 'efficient', 'i', 'find', 'it', 'fascinating', 'how', 'technology', 'connects', 'people', 'across', 'the', 'world', 'in', 'real', 'time', 'it', 'also', 'plays', 'a', 'major', 'role', 'in', 'fields', 'like', 'medicine', 'education', 'and', 'entertainment', 'new', 'innovations', 'like', 'virtual', 'reality', 'and', 'smart', 'devices', 'continue', 'to', 'change', 'how', 'we', 'experience', 'the', 'world', 'overall', 'technology', 'is', 'an', 'exciting', 'and', 'powerful', 'tool', 'that', 'keeps', 'pushing', 'the', 'limits', 'of', 'what', 's', 'possible']\n",
            "\n",
            "Words starting with a vowel: ['is', 'one', 'of', 'it', 'evolves', 'and', 'our', 'artificial', 'intelligence', 'it', 'and', 'efficient', 'i', 'it', 'across', 'in', 'it', 'also', 'a', 'in', 'education', 'and', 'entertainment', 'innovations', 'and', 'experience', 'overall', 'is', 'an', 'exciting', 'and', 'of']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q4. Custom TokenizaƟon & Regex-based Text Cleaning\n",
        "# 1. Take original text from QuesƟon 1.\n",
        "# 2. Write a custom tokenizaƟon funcƟon that:\n",
        "# a. Removes punctuaƟon and special symbols, but keeps contracƟons (e.g.,\n",
        "# \"isn't\" should not be split into \"is\" and \"n't\").\n",
        "# b. Handles hyphenated words as a single token (e.g., \"state-of-the-art\" remains\n",
        "# a single token).\n",
        "# c. Tokenizes numbers separately but keeps decimal numbers intact (e.g., \"3.14\"\n",
        "# should remain as is).\n",
        "# 3. Use Regex SubsƟtuƟons (re.sub) to:\n",
        "# a. Replace email addresses with '<EMAIL>' placeholder.\n",
        "# b. Replace URLs with '<URL>' placeholder.\n",
        "# c. Replace phone numbers (formats: 123-456-7890 or +91 9876543210) with\n",
        "# '<PHONE>' placeholder.\n",
        "# 1. Custom tokenization function\n",
        "def custom_tokenizer(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^\\w\\s\\'-]', '', text)\n",
        "    return word_tokenize(text)\n",
        "\n",
        "custom_tokens = custom_tokenizer(text)\n",
        "print(\"\\nCustom Tokenized Text:\", custom_tokens)\n",
        "\n",
        "# 2. Regex substitutions for cleaning\n",
        "# a. Replace email addresses with '<EMAIL>'\n",
        "text_with_emails = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b', '<EMAIL>', text)\n",
        "# b. Replace URLs with '<URL>'\n",
        "text_with_urls = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '<URL>', text_with_emails)\n",
        "# c. Replace phone numbers with '<PHONE>'\n",
        "text_cleaned = re.sub(r'(\\+?\\d{1,2}\\s?)?(\\(?\\d{3}\\)?[-.\\s]?\\d{3}[-.\\s]?\\d{4})', '<PHONE>', text_with_urls)\n",
        "\n",
        "print(\"\\nText with Emails, URLs, and Phone Numbers Replaced:\")\n",
        "print(text_cleaned)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7uAVyZnGHaB",
        "outputId": "86ec4d5a-9658-4a2f-9bd1-e8af2be0afbe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Custom Tokenized Text: ['technology', 'is', 'one', 'of', 'my', 'favorite', 'topics', 'because', 'it', 'constantly', 'evolves', 'and', 'shapes', 'our', 'daily', 'lives', 'from', 'smartphones', 'to', 'artificial', 'intelligence', 'it', 'makes', 'tasks', 'faster', 'and', 'more', 'efficient', 'i', 'find', 'it', 'fascinating', 'how', 'technology', 'connects', 'people', 'across', 'the', 'world', 'in', 'real', 'time', 'it', 'also', 'plays', 'a', 'major', 'role', 'in', 'fields', 'like', 'medicine', 'education', 'and', 'entertainment', 'new', 'innovations', 'like', 'virtual', 'reality', 'and', 'smart', 'devices', 'continue', 'to', 'change', 'how', 'we', 'experience', 'the', 'world', 'overall', 'technology', 'is', 'an', 'exciting', 'and', 'powerful', 'tool', 'that', 'keeps', 'pushing', 'the', 'limits', 'of', 'whats', 'possible']\n",
            "\n",
            "Text with Emails, URLs, and Phone Numbers Replaced:\n",
            "Technology is one of my favorite topics because it constantly evolves\n",
            " and shapes our daily lives. From smartphones to artificial intelligence, it\n",
            "  makes tasks faster and more efficient. I find it fascinating how technology\n",
            "   connects people across the world in real time. It also plays a major role in\n",
            "    fields like medicine, education, and entertainment. New innovations like\n",
            "     virtual reality and smart devices continue to change how we experience the\n",
            "      world. Overall, technology is an exciting and powerful tool that keeps\n",
            "       pushing the limits of what’s possible.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}
